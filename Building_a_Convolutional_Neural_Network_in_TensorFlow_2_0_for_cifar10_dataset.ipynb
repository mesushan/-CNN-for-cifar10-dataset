{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Building a Convolutional Neural Network in TensorFlow 2.0 for cifar10 dataset.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mesushan/-CNN-for-cifar10-dataset/blob/master/Building_a_Convolutional_Neural_Network_in_TensorFlow_2_0_for_cifar10_dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TtKPA0APFaDf",
        "colab_type": "text"
      },
      "source": [
        "[Data source for CIFAR10](https://www.cs.toronto.edu/~kriz/cifar.html)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zJMS8p3wfPXO",
        "colab_type": "text"
      },
      "source": [
        "## Step 1: Installing dependencies and notebook gpu setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PXNUanZvcwwZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install tensorflow-gpu==2.1-rc0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lRHFdNYAfWKJ",
        "colab_type": "text"
      },
      "source": [
        "## Step 2: Importing the libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tS5xFeQwe9Xu",
        "colab_type": "code",
        "outputId": "37b89e58-c1dc-4251-dc15-5802d2385ba4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "\n",
        "%matplotlib inline\n",
        "tf.__version__"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.1.0-rc0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e8zYubaPfy-S",
        "colab_type": "text"
      },
      "source": [
        "## Step 3: Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AOAGjiPogF0w",
        "colab_type": "text"
      },
      "source": [
        "### Loading the Cifar10 dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v1N6LbS-e9a1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Setting the class names in the dataset\n",
        "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f13-8-m_fqKP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Loading the dataset\n",
        "(X_train, y_train), (X_test, y_test) = cifar10.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XqDIpsJWgUkz",
        "colab_type": "text"
      },
      "source": [
        "### Normalizing the image\n",
        "Dividing each pixels of image by 255 so that all the pixels of images will be in the range of 0 and 1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-QFncPlpgNmU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = X_train / 255.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L1rFHX67gc6G",
        "colab_type": "code",
        "outputId": "dd2bd8e1-5337-4d24-bc15-c6dbe1da7046",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 32, 32, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JemAE1oNKx4S",
        "colab_type": "text"
      },
      "source": [
        "first dimension is the index of the image, 2nd and 3rd are the 2*2 dimension of the image and the last is the RGB format containing the three channels of red, green and blue which makes color.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ve2WbRGWgc3I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_test = X_test / 255.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7jwvNZ82gh9d",
        "colab_type": "code",
        "outputId": "de462236-7a85-4b5e-e3ad-0536f08154f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "source": [
        "plt.imshow(X_test[1])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fd3a1c45a20>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD5CAYAAADhukOtAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nLkQmKNiFyIR/Aqr65gVBTj9UAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HXiuZulIguyf",
        "colab_type": "text"
      },
      "source": [
        "## Step 4: Building a Convolutional Neural Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZFTetk8ngy0f",
        "colab_type": "text"
      },
      "source": [
        "### Defining the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1TR0JGP5gq2i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = tf.keras.models.Sequential()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j92d4FE0hTZV",
        "colab_type": "text"
      },
      "source": [
        "### Adding the first convolutional layer\n",
        "\n",
        "CNN layer hyper-parameters to be used:\n",
        "\n",
        "    filters: 32\n",
        "    kernel_size: 3\n",
        "    padding: same\n",
        "    activation: relu\n",
        "    input_shape: (32, 32, 3)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LSkL1iOvg_dE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, padding=\"same\", activation=\"relu\", input_shape=[32, 32, 3]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gfRAaRmWiSlZ",
        "colab_type": "text"
      },
      "source": [
        "### Adding the second convolutional layer and the max-pooling layer\n",
        "\n",
        "CNN layer hyper-parameters to be used:\n",
        "\n",
        "    filters: 32\n",
        "    kernel_size:3\n",
        "    padding: same\n",
        "    activation: relu\n",
        "\n",
        "MaxPool layer hyper-parameters to be used:\n",
        "\n",
        "    pool_size: 2\n",
        "    strides: 2\n",
        "    padding: valid\n",
        "\n",
        "Note: Strides is an argument of a Conv layer and with  this parameter, we can define the number of pixels a kernel can move in any direction and analyses the input image.\n",
        "\n",
        "[Difference between 'same' and 'valid' padding explained here](https://www.corvil.com/kb/what-is-the-difference-between-same-and-valid-padding-in-tf-nn-max-pool-of-tensorflow)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sSl7Es5yidMp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, padding=\"same\", activation=\"relu\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wmP9h5wliAR6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2, padding='valid'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wd8ERDyvin-0",
        "colab_type": "text"
      },
      "source": [
        "### Adding the third convolutional layer\n",
        "\n",
        "CNN layer hyper-parameters:\n",
        "\n",
        "    filters: 64\n",
        "    kernel_size:3\n",
        "    padding: same\n",
        "    activation: relu\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i9HWy6aFixEw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.add(tf.keras.layers.Conv2D(filters=64, kernel_size=3, padding=\"same\", activation=\"relu\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O55kyOQGi44V",
        "colab_type": "text"
      },
      "source": [
        "###  Adding the fourth convolutional layer and max-pooling layer\n",
        "\n",
        "CNN layer hyper-parameters:\n",
        "\n",
        "    filters: 64\n",
        "    kernel_size:3\n",
        "    padding: same\n",
        "    activation: relu\n",
        "\n",
        "MaxPool layer hyper-parameters:\n",
        "\n",
        "    pool_size: 2\n",
        "    strides: 2\n",
        "    padding: valid\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5b7vAuhjjCF2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.add(tf.keras.layers.Conv2D(filters=64, kernel_size=3, padding=\"same\", activation=\"relu\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oc493G2BjFhg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2, padding='valid'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-hGnR3aXjKbZ",
        "colab_type": "text"
      },
      "source": [
        "### Adding the flattening layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QLzu2cCVjI5Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.add(tf.keras.layers.Flatten())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GpeRUvVWjR1W",
        "colab_type": "text"
      },
      "source": [
        "### Adding the first fully-connected layer\n",
        "\n",
        "Dense layer hyper-parameters:\n",
        "    units/neurons: 128\n",
        "    activation: relu"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FWzYY8kKjhnZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.add(tf.keras.layers.Dense(units=128, activation='relu'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UaakKTqRjrkF",
        "colab_type": "text"
      },
      "source": [
        "### Adding the output layer\n",
        "\n",
        "Dense layer hyper-parameters:\n",
        "\n",
        "    units/neurons: 10 (number of classes)\n",
        "    activation: softmax\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4t-JmzRvjnBj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.add(tf.keras.layers.Dense(units=10, activation='softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aRr3bCU-ti06",
        "colab_type": "code",
        "outputId": "5bd5c1cf-cf08-49ed-f049-eaa7acdc3ad5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 32, 32, 32)        9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 16, 16, 64)        18496     \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 16, 16, 64)        36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 128)               524416    \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 591,274\n",
            "Trainable params: 591,274\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DYgvbNihtprw",
        "colab_type": "text"
      },
      "source": [
        "### Compiling the model\n",
        "\n",
        "#### sparse_categorical_accuracy\n",
        "sparse_categorical_accuracy checks to see if the maximal true value is equal to the index of the maximal predicted value.\n",
        "\n",
        "[Difference between categorical accuracy and sparse categorical accuracy](https://stackoverflow.com/questions/44477489/keras-difference-between-categorical-accuracy-and-sparse-categorical-accuracy) "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oYHELxz4tsa-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"Adam\", metrics=[\"sparse_categorical_accuracy\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gox3SmwUtwgX",
        "colab_type": "text"
      },
      "source": [
        "### Training the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D3MHvRYKe9fN",
        "colab_type": "code",
        "outputId": "44714925-fee4-4860-9824-0c206bca6e9b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "model.fit(X_train, y_train, epochs=5)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 50000 samples\n",
            "Epoch 1/5\n",
            "50000/50000 [==============================] - 10s 199us/sample - loss: 1.3540 - sparse_categorical_accuracy: 0.5109\n",
            "Epoch 2/5\n",
            "50000/50000 [==============================] - 7s 133us/sample - loss: 0.9153 - sparse_categorical_accuracy: 0.6773\n",
            "Epoch 3/5\n",
            "50000/50000 [==============================] - 7s 133us/sample - loss: 0.7410 - sparse_categorical_accuracy: 0.7397\n",
            "Epoch 4/5\n",
            "50000/50000 [==============================] - 7s 133us/sample - loss: 0.6146 - sparse_categorical_accuracy: 0.7860\n",
            "Epoch 5/5\n",
            "50000/50000 [==============================] - 7s 134us/sample - loss: 0.5144 - sparse_categorical_accuracy: 0.8185\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fd39003e0b8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D8C7Pm0NuOrJ",
        "colab_type": "text"
      },
      "source": [
        "### Evaluating the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z9r8TtNet3D0",
        "colab_type": "code",
        "outputId": "abb70ab9-c221-44ca-d51f-6fd7d99e2613",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "test_loss, test_accuracy = model.evaluate(X_test, y_test)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 1s 95us/sample - loss: 0.8031 - sparse_categorical_accuracy: 0.7378\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0rpAPpfzuV0p",
        "colab_type": "code",
        "outputId": "db3ead20-7f5e-4b00-860b-61173895637d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(\"Test accuracy: {}\".format(test_accuracy))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test accuracy: 0.7378000020980835\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cMW_T5PmU18p",
        "colab_type": "text"
      },
      "source": [
        "From this model, we get the accuracy of 73% in test dataset but approx 82% in the testing dataset which shows a sign of overfitting. In the next model, lets see if we can improve the model."
      ]
    }
  ]
}